\documentclass[lettersize, noapacite, twoside, HRI]{apa_HRI}


%\usepackage[utf8x]{inputenc}
\usepackage{times}

\usepackage{graphicx} 
\usepackage{subfigure}
\usepackage{paralist}

\usepackage{hyperref}

\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{url}
\usepackage{xspace}
\usepackage{booktabs}

\usepackage[natbibapa]{apacite}


\usepackage{tikz}
\usetikzlibrary{shapes,positioning,calc,decorations.pathreplacing}
\newcommand{\tikzmark}[1]{\tikz[overlay,remember picture] \node (#1) {};}

\usepackage[draft,nomargin,footnote]{fixme}

\graphicspath{{figs/}}

\newcommand{\eg}{\textit{e.g.}\xspace}
\newcommand{\etal}{\textit{et al.}\xspace}
\newcommand{\ie}{\textit{i.e.}\xspace}
\newcommand{\etc}{\textit{etc.}\xspace}
\newcommand{\vs}{\textit{vs.}\xspace}

\newcommand{\h}[1]{\textbf{H#1}\xspace}

\newcommand{\anti}{{$\mathcal{A}_0$\xspace}}
\newcommand{\antf}{{$\mathcal{A}_1$\xspace}}
\newcommand{\deltaant}{{ $\Delta_{\mathcal{A}_0,\mathcal{A}_1}$\xspace}}


\rightheader{Shaping the Perception of a Robot by Cognitive Priming}   % This should be the title, or a shortened version of the title if your title is long.
\leftheader{Lemaignan et al.}	  % For one or two authors, include both authors last names.  For three or more, use first author's last name et al.
\title{Shaping the Perception of a Robot as a Human-Like Agent by Cognitive
Priming}

\author{S\'everin Lemaignan, Kshitij Sharma, Ashish Ranjan Jha, Pierre
Dillenbourg}
\affiliation{CHILI Lab, \'Ecole Polytechnique F\'ed\'erale de Lausanne}

\acknowledgements{\url{firstname.lastname@epfl.ch}}

\abstract{
What leads us to perceive robots as human-like agents? The physical appearance
of the robot and the design of its behaviours (the anthropomorphic \emph{design}
of the robot) do certainly play an important role. This paper sheds light on
another mechanism at play, less obvious because partially unconscious: the
cognitive skills that the interaction situation presupposes.

We evidence this effect with a novel methodology based on eye-tracking
and a set of stimuli that are visually identical and yet induce different
assumptions regarding the cognitive capabilities of the robot. By correlating
the resulting gaze patterns with answers to established questionnaires on
anthropomorphic attributions, we show that fixations on the head of the robot
indeed reflect how we perceive the machine.

Interestingly, we also show that humans appear quite sensitive to this effect:
even subtle context priming is sufficient to elicit significantly different
anthropomorphic attributions, and as such, this article provides new insights on
how our expectations of the robot's cognitive competency shape the bonds that we
build with the machine.

}

\keywords{human-robot interaction, anthropomorphism, cognitive priming, eye-tracking, gaze patterns}

\begin{document}
\maketitle

\section{Introduction}

Researchers in robotics often tend to see anthropomorphism as the static set of
human-like features of a robot (like its shape, its speech capabilities, facial
expressions, etc.). Following~\citet{fink_anthropomorphism_2012}, we refer to
these characteristics as the \emph{anthropomorphic design} of the robot, and we
call instead \emph{anthropomorphism} the \emph{social phenomenon} that arises
from the (real or imagined) interaction between a non-human agent (a robot in
our case) and a human~\citep{persson_anthropomorphism_2000}. As such,
anthropomorphism includes the perception of emotional states, motivations,
intentions in the non-human agent, and, conversely, the ascriptions of those
qualities to them~\citep{epley_when_2008}.

Being such a central ingredient of the psychological ``sauce'' that binds humans to
robots, the field of human-robot interaction (HRI) has long~\fixme{ref?}
attempted to manipulate the anthropomorphic attributes we ascribe to robots.
While modifying the anthropomorphic \emph{design} of robots is conceptually
easy, influencing the underlying psychological phenomenon is less
obvious, although likely more effective.

One way consists in manipulating the context of use of the robot: when social,
entertaining or playful, it elicits more anthropomorphic attributions compared
routine or focused, serious situations (security, rescue, \etc).
\citet{joosse_what_2013} showed, for instance, that when the same robot (a {\sc
nao} humanoid) was used in a different task context (cleaning task \vs tour
guide), users would ascribe different personalities to the robot. Along the same
line, \citet{goetz_cooperation_2002} found that people prefer a serious robot
for serious tasks and a less serious robot for more playful tasks. Also related,
\citet{kaplan_free_2000} discussed how the uselessness of the robot impacts our
tendency to anthropomorphize it: artificial pets like AIBO have no real purpose,
in a sense that they do not provide any kind of service, and this very aspect
may increase people's tendency to anthropomorphize them.

We may hypothesize that these results are a consequence of different
expectations we form about the robot depending on the context: when a machine is
embedded in a social situation, for instance, we expect it to exhibit certain
social skills. However, the experiments conducted so far explore prototypical
opposite situations (routine \vs playful, typically boring \vs typically
intellectual): while they do confirm that the interaction context impacts our
perception of the robot, the stark contrast of the conditions makes it difficult
to finely analyse the psychological determinants that explain the different
perception of the robot.\fixme{references are needed} In particular, existing
techniques to measure anthropomorphism traditionally rely on questionnaires that
may suffer post-hoc reconstruction (we come back on this hereafter).

This article attempts to address this issue with a different experimental design
and a novel methodology to measure \emph{in-the-moment} anthropomorphic attributions.
Our approach is built on a combination of cognitive priming and eye-tracking,
and evidences specific gaze fixations on the head of the robot when the
participants are primed with higher expectations regarding the cognitive skills
of the robot.


\subsection{Cognitive Priming and Interaction Situation}

\textbf{TBD: Kshitij} at the end of this section, the reader must be convinced
that:
\begin{itemize}
    \item cognitive priming is a well established technique, grounded in the
        litterature,
    \item our terminology ('shallow' vs 'deep') is meaningful, and grounded
    \item our cognitive priming would impact the perception of the interaction
        situation as machine-like vs human-like (to support our manipulation
        check!)
\end{itemize}

\subsection{Measuring Anthropomorphism}

Assessing anthropomorphic attributions during a human-robot interaction is an
indirect mean to explore the intricate -- and dynamic -- bonds that build up
between the robot and its human partner. As such, a lot of literature in HRI has
investigated means of measuring anthropomorphism. This indeed raises interesting
methodological challenges, if only because of high inter-personal variations in
one's tendency to anthropomorphize~\fixme{ref?}, and the dynamic nature of
anthropomorphic attributions~\citep{lemaignan2014dynamics}.

One phenomenon requires particular attention: well established in the
psychological literature in terms of \emph{impulsive} or \emph{automatic} \vs
\emph{reflective} behaviours~\citep{strack2004reflective}, the way we behave and
perceive \emph{in-the-moment} is significantly different from what results from
a thoughtful (and slower) reflection on the situation. As noted by
\citet{takayama_perspectives_2012} for instance, this also impacts our
perspective on agency, and in fact, as shown by~\citet{nass_machines_2000}, in
the first phase of interaction with a robot, people might respond mindlessly,
and only after the so-called \emph{familiarization} period, one might respond in
a more conscious, reflective manner. The typical illustration of this mechanism
is found in~\citet{reeves_media_1996} who showed that participants who would
interact with technologies in ways similar to how they interact with people,
would however {\it a posteriori} typically deny having performed an human-like
interaction.

Yet, most of the methodologies available to assess anthropomorphic ascriptions
in HRI are limited to post-interaction measurement, mainly in the form of closed
questionnaires or rating scales. The Godspeed
questionnaire~\citep{bartneck_measurement_2008}, and in particular, its subpart
focused on anthropomorphism, is the main validated questionnaire to assess
anthropomorphism. On 5-points semantic differential scales, people are asked to
rate the following constructs: fake \vs natural, machinelike \vs humanlike,
unconscious \vs conscious, artificial \vs lifelike, moving rigidly \vs moving
elegantly. Because the concept of ``human-likeness'' itself is complex and
abstract, \citet{kahn_jr._robotic_2006} suggest to ask for more concrete
constructs that are typical or unique of the concept of ``human-likeness'', and
\citet{ruijten_introducing_2014} propose for instance a 25-item questionnaire to
measure various concrete aspects of human-likeness. Other
researchers~\citep{zlotowski2014dimensions,salem2015would} also applied a
two-dimensional scale measuring \emph{Human Nature} and \emph{Uniquely Human}
traits of robots, based on an original proposal by
\citet{haslam2008attributing}.

We explore hereafter a different approach to measure anthropomorphism, based on
eye-tracking. By looking at the eyes fixation on the head of the robot, we show
significantly different gazing behaviours in two experimental conditions that
differ in terms of the (projected) robot's human-likeness. This eye-tracking
based metric is behavioural -- hence not prone to post-hoc reconstruction by the
participants -- and \emph{in-the-moment} -- mitigating the impact of a reflective
elaboration on the nature of the human-robot interaction. We believe that these
two improvements over existing techniques provide a solid ground for the study
of the socio-cognitive bonds that establish between humans and robots when they
interact.

\subsection{Hypotheses}

\begin{inparaenum}[\itshape a\upshape)]
Two nested research questions have been presented so far: \item can we
characterize the link between expectations regarding the cognitive
skills of a robot and the effective ascription of anthropomorphic features to
this robot; and \item to this end, can we develop and validate a behavioural and
\emph{in-the-moment} metric of anthropomorphism?  \end{inparaenum}

These two questions translate into several experimental hypotheses, whose design
was guided by the following intuition: \emph{the more we ascribe cognitive
capabilities to an agent, the more likely we are to focus on its head when
interacting with it}, which suggests an eye-tracking-based investigation.

%Eye-tracking-based technique logically follows as an investigation mean, is a natural
%methodology to investigate this intuition. We hence design audio-visual stimuli
%that elicit different levels of cognitive ascription onto the robot while being
%identical in every other way.


Our baseline hypothesis \h{1} is that cognitive priming allows us to effectively create
stimuli that induce \emph{shallow} or \emph{higher} expectations regarding the
cognitive skills of the robot. This hypothesis is to be tested by asking
participants to rate the interactions depicted by the stimuli as being more
\emph{machine-like} (low ascription of cognitive skills) or \emph{human-like}
(higher expectation of cognitive competency).

Secondly, we hypothesize that people with a higher tendency to anthropomorphize
robots will tend to look at robots and humans in similar ways, contrary to
people with a lower tendency to anthropomorphize (\h{2}). If this is verified,
it supports the idea that anthropomorphic attributions affect gaze patterns. The
hypothesis can be tested by correlating the participants' tendency to
anthropomorphize, measured from a standard questionnaire, with the comparative
gazing behaviour in two conditions (human task \vs robot task).

Third, we hypothesize that in the \emph{human-like} condition (higher ascription
of cognitive skills to the robot), the participants' gaze will be directed
significantly more towards the head of the robot than in the \emph{machine-like}
condition (low ascription of cognitive skills) (\h{3}). If verified, it
effectively means that the expectations held by the participants regarding the
cognitive capabilities of the robot are reflected by the eye fixations on the
head of the robot.  The hypothesis can be tested by comparing gaze fixations in
the two conditions (\emph{human-like} \vs \emph{machine-like}).

Finally, the hypothesis \h{4} proposes that manipulating cognitive expectations
affects the broader tendency to anthropomorphize robots, \ie whether observing one
robot acting in an \emph{human-like} context leads to an increased level of
anthropomorphic attributions to robots in general. The hypothesis can be
tested by looking at pre- and post-experiment self-reports on the tendency to
anthropomorphize.

If all these hypotheses are verified, the findings can be summarized as follow:
\h{1} shows that our manipulation (based on cognitive priming) does effectively
elicit lower or higher expectations in terms of the cognitive capabilities of
the robot; \h{4} shows that these expectations influence our tendency to
anthropomorphize robots; in parallel, \h{3} shows that these same expectations
shape the way we look at the robot by eliciting specific eye fixations on the
head of the robot; finally, \h{2} suggests that the fixation on the head
reflects human-likeliness and supports the thesis that head fixation can be used
as a behavioural measure of anthropomorphism.

%Figure~\ref{hyps} illustrate how these four hypotheses relate to \emph{a)}
%cognitive priming, \emph{b)} anthropomorphic attributions, and \emph{c)} gaze
%patterns.
%
%\begin{figure}[ht]
%\centering
%
%\resizebox{0.5\linewidth}{!}{%
%
%\begin{tikzpicture}[
%    >=latex,
%    every edge/.style={->,draw, very thick},
%    every node/.style={draw, circle, text centered, text width=2.7cm}]
%
%    \node at (0,0) (ctxt) {cognitive priming};
%    \node at (-3,-3) (anthro) {Anthropomorphic attributions};
%    \node at (3,-3)[circle split, text width=2.5cm] (gaze) {\textit{\small Fixations \\on head} \nodepart{lower} \textit{\small Gaze
%distribution \\differences}};
%    \node [draw=none,anchor=east,left=-0.5cm of gaze.west] (gazecap) {\large Gaze:};
%
%    \path[every node/.style={draw=none}]
%            (ctxt) edge [bend right] node[left] {\h{1}, \h{4}} (anthro)
%            (ctxt) edge [bend left] node[right] {\h{3}} (gaze.north)
%            (anthro) edge [bend right] node[above] {\h{2}} (gaze.south);
%\end{tikzpicture}
%}
%
%\caption{Hypotheses of interactions between the three main concepts studied in
%the article. Arrows mean ``A impacts B''.}
%
%    \label{hyps}
%\end{figure}


\section{Experimental Design}


This study is build as an eye-tracking experiment (using a stationary
eye-tracker SMI RED 250) where participants watch short videos of an agent --
either a robot (Aldebaran Robotics' Nao) or a human -- performing simple
task (picking an object or pointing toward a sound source) after being primed.
The priming is designed to elicit either shallow cognitive ascriptions onto the
robot (leading to a \emph{machine-like} situation) or deeper cognitive
ascriptions (leaning toward a \emph{human-like} situation).

Besides eye-tracking, the participants' perception of robots is assessed through a
pre- and a post-questionnaire, described below.

\subsection{Conditions}

The study follows a 2$\times$2 design, summarized in table~\ref{table:design}.
Our two independent variables are the level of cognitive priming (\emph{shallow}
\vs \emph{deep}) and the nature of the agent appearing in the stimulus (a robot,
eliciting a \emph{human-robot} interaction situation, or a human, eliciting a
\emph{human-human} interaction situation).

\begin{table}[ht!]
    \vspace{2em}
    \centering
    \small

    \tikzmark{top}

    \tikzmark{left}
    \begin{tabular}{l|p{4cm}|p{4cm}}
        & \tikzmark{top1} Shallow cognitive priming & Deep cognitive priming \tikzmark{top2}  \\
        \hline
        \tikzmark{left1} Robot & {\bf A}: \emph{``Pick the brown toy''} & {\bf A}: \emph{``Pick your favorite toy''} \\
                               & {\bf B}: \emph{``Point at the noise''} & {\bf B}: \emph{``Point at the crying baby''} \\
        \hline
        \tikzmark{left2} Human & {\bf A}: \emph{``Pick the brown toy''} & {\bf A}: \emph{``Pick your favorite toy''} \\ 
                               & {\bf B}: \emph{``Point at the noise''} & {\bf B}: \emph{``Point at the crying baby''}\tikzmark{bottom} \\
        \end{tabular}

    % draw the over- and side-braces
    \begin{tikzpicture}[overlay, remember picture]

        \draw [decoration={brace,amplitude=0.5em},decorate,thick]
        (top -| top1.west) --  (top -| bottom.east) node[midway, above=0.5em] {\scriptsize between subjects};

        \draw [decoration={brace,amplitude=0.5em},decorate,thick]
        ($(left |- bottom)+(1.8,-0.3)$) --  ($(left |- left1.north)+(1.8,0.2)$) node[midway,above=3em,left=1em,rotate=90] {\scriptsize within subject};
    \end{tikzpicture}
    %%%

    \caption{\small The study follows a 2$\times$2 design: the \emph{robot} vs
        \emph{human} condition is within subject, while the \emph{shallow
        cognitive priming} \vs \emph{deep cognitive priming} is between subjects.
        Two stimuli (\emph{Picking} task, {\bf A}, and \emph{Pointing} task,
        {\bf B}) were shown to the participants, introduced by brief verbal
        commands, reproduced in the table. Figure~\ref{fig:stimuli} shows
        pictures of the four stimuli.}

    \label{table:design}
\end{table}


\subsection{Video Stimuli}

Four different video stimuli where filmed (figure~\ref{fig:stimuli}): two
different tasks (picking a stuffed animal, refered hereafter as the
\emph{Picking} task, and pointing towards a source of sound, refered as the
\emph{Pointing} task) acted either by a human or a robot. Video stimuli were
realised in studio conditions. All videos followed the same simple structure: an
initial audio command (spoken by an invisible person), followed by the task
being executed.

The human actor was instructed to follow as closely as possible the actions and
attitudes of the robot (left/right glances, hesitations, gestures), while keeping a
natural, \emph{human-like} general behaviour. As a result, the length of human videos
(57 seconds in total for the two tasks) was shorter than robot videos (110
seconds) due to the robot being usually slower in performing actions (in
particular walks) compared to human.\footnote{To make sure the difference of
video lenght does not bias gaze distributions, we ran a $\chi^2$ test between
the gaze distributions of the first half and the second half of the robot
videos: no significant difference was found ($\chi^2[DF=4]=.0066, p=1$).}

The audio (and audio only) of these four videos was then edited to create two
sets of stimuli: one for the \emph{shallow cognitive priming} condition, one for
the \emph{deep cognitive priming} condition. The audio editing consisted in
inserting different commands to initiate the tasks (reported in
table~\ref{table:design}): in the \emph{Picking} task for instance, the object
that the agent had to pick was described either as a \emph{``brown toy''} or as
\emph{``your favorite toy''}. In the former case, the object was refered through
visible, objective features which do not suppose as deep cognitive capabilities
as in the latter case where the agent is implicitly supposed to have
tastes and preferences such as it can choose a toy as its favorite.

This simple verbal priming (\emph{``brown toy''} \vs \emph{``your favorite
toy''}) set the expectations regarding the cognitive capabilities of the robot
(\emph{shallow} \vs \emph{deep}) and was expected to lead to different
perceptions of the interaction (\emph{machine-like} \vs \emph{human-like}). We
reinforced this effect in the \emph{Pointing} task: not only the verbal priming
but also the sound played by the speakers during the task was altered: either a
repetitive bip (\emph{shallow cognitive priming}) or the sound of a crying baby
(\emph{deeper cognitive priming}).

\begin{figure}
    \centering
    \subfigure[\emph{Picking} task, robot condition]{
        \includegraphics[height=5cm]{stimulus-robot-toys}
    }
    \subfigure[\emph{Picking} task, human condition]{
        \includegraphics[height=5cm]{stimulus-human-toys}
    }

    \subfigure[\emph{Pointing} task, robot condition]{
        \includegraphics[height=5cm]{stimulus-robot-noise}
    }
    \subfigure[\emph{Pointing} task, human condition]{
        \includegraphics[height=5cm]{stimulus-human-noise}
    }


    \caption{\small Screenshots of the 2$\times$2 stimuli. Note that the images above have been
    slightly cropped: the original video are framed so that the agent (robot or
    human) always remains entirely visible.}
    \label{fig:stimuli}
\end{figure}

Section~\ref{stimuli_design}, at the end of the article, specifically discusses
the design constraints that were accounted for while creating the above stimuli.

\subsection{Questionnaires}

Before starting the experiment, the participants were asked to fill a
pre-questionnaire which had 49 questions (5-point Likert scale). The
questionnaire comprised of questions assessing their familiarity with robots, 10
items from the \emph{Big-Five} personality questionnaire, 15 questions taken from
Godspeed questionnaire (questions related to \emph{anthropomorphism},
\emph{likeability} and \emph{perceived intelligence}) and 20 questions rating
human-likeness (from~\cite{ruijten_introducing_2014})\footnote{The
pre- and post-questionnaires are available online:
\url{https://github.com/chili-epfl/anthropomorphism-eyetracking}.}. The pre-questionnaire
typically took 5 minutes for participants to fill. The results were turned into
a score noted \anti{} (\emph{initial tendency to anthropomorphize}) following a
method presented below (section~\ref{questionnaires_processing}).

The post-questionnaire was administered at the end of the experiment, and was
identical to the pre-questionnaire, except that the personality questions were omitted and a
manipulation check question was added (\emph{``In your opinion, the tasks that
you watched were more: A robot kind of task ... A human kind of task''}, on a 5
points scale).
This questionnaire typically took 3 to 4 minutes to fill. The resulting score is
noted \antf{} (\emph{final tendency to anthropomorphism}).

\anti{}, \antf{} and the difference \deltaant measured for each participant between
the pre- and post-questionnaires form the dependent variables of our experiment.
\deltaant, in particular, reflects the impact of the video stimuli on the
anthropomorphic perception that they have of robots \emph{in general}: the
Godspeed questions used in the questionnaires are not specific to the Nao robot
used in this particular experiment, and indeed assess how humans perceive robots
in a broad sense.

\section{Method}


%Figure~\ref{course_of_study} gives an overview of the protocol, detailed
%hereafter.
%
%\begin{figure}[ht]
%\centering
%
%\begin{tikzpicture}[
%    >=latex,
%    every edge/.style={<-,draw, very thick},
%    every node/.style={draw, text centered, text width=5cm}]
%
%    \node (n1) at (0,0) {Consent form};
%    \node (n2) [below=of n1] {Familiarization}
%        edge (n1);
%    \node (n3) [below=of n2] {Pre-questionnaire}
%        edge (n2);
%    \node (n4) [below=of n3] {Videos}
%        edge (n3);
%    \node (n5) [below=of n4] {Post-questionnaire}
%        edge (n4);
%
%\end{tikzpicture}
%    \caption{Overview of the course of the study}
%    \label{course_of_study}
%\end{figure}

\subsection{Participants}

We ran the study with 56 participants ($M = 20.9$ years old, $SD = 3.9$, 31 females and
25 males).  The participants were recruited amongst students of our university.
To avoid students with a high familiarity with robots and artificial intelligent
systems, Computer Science and Electronics curriculum were excluded. This was
\textit{a posteriori} comforted by the questionnaire responses: no participants
reported itself as being very familiar with robots, 8 reported some familiarity
and 7 out of 56 owned a domestic robot (vacuum cleaner).

As stated previously, the study follows a 2$\times$2 design
(table~\ref{table:design}): the \emph{shallow} \vs \emph{deep cognitive priming}
condition was between-subjects (30 participants performed the \emph{deep cognitive}
tasks while 26 were in the \emph{shallow cognitive} condition); the \emph{robot}
\vs \emph{human} condition was within-subject (the order of stimuli presentation
was counter-balanced over the participants). The study lasted in average 15
minutes per participant.

\subsection{Procedure}

\subsubsection{Familiarization and Pre-questionnaire}

Before starting the experiment, participants were made to read, understand and sign a
consent form. Participants were then asked to fill the 49 questions of
the pre-questionnaire, with a 10 minutes time limit (that none of the participants
reached).

After the pre-questionnaire, we invited the participants to an initial
free interaction with a powered-off Nao robot (we did not constraint
the time, and participants played between 2 and 3 minutes with the robot).
The purpose of this pre-interaction was to get the participants acquainted with the
robot appearance, shape and range of motions it could possibly perform, so as to
mitigate the (visual) novelty of the robot that would lead to hard-to-measure gaze artifacts.

\subsubsection{Stimuli Screening}

After filling the pre-questionnaire, we conducted a brief eye-tracker
calibration procedure, and the participants' gaze was recorded while they
watched the \emph{robot} and \emph{human} interaction stimuli.

\subsubsection{Post-questionnaire and Conclusion}

Finally, the participants were asked to fill a post-questionnaire.
Before leaving, possible questions on the purpose of the study were
answered and each participant was given a reward equivalent to EUR 10.

\subsection{Measures}

\subsubsection{Gaze Variables}

As seen in figure~\ref{fig:aoi}, we defined 10 Areas of Interest (AOIs): one on
the head of the agent (robot or human), two on the arms (left and right), two on
the hands, two on the legs and one on the torso. Besides, we defined one area of
interest per toy or speaker (depending on the stimulus).

\begin{figure}
    \centering
    \subfigure[\emph{Picking} task, robot condition]
    {\includegraphics[height=5cm]{aoi-robot}\label{fig:aoi-toys}}
    \subfigure[\emph{Pointing} task, human condition]
    {\includegraphics[height=5cm]{aoi-human}\label{fig:aoi-noise}}

    \caption{Areas of Interest (AOIs) used for the gaze analysis}
    \label{fig:aoi}
\end{figure}

We recorded the fixations on each of these zones and normalized them by
the full duration of the video stimulis and the surface of AOIs between the robot
and human conditions. We finally analyzed their distribution, producing what we call \emph{gaze
patterns}.

To compare gazing behaviours across the robot and human conditions, we besides
computed a \emph{gaze distribution difference} over the 10 AOIs ($N=10$):

{\Large
\[
    \delta_{\mathcal{H}, \mathcal{R}}^{\text{gaze}} =
    \frac{\sum\limits_{{\text{{\sc aoi}s}}}\left |
    \frac{\text{Time}_{\text{Human}}^{\text{\sc
aoi}}}{\text{Area}_{\text{Human}}^{\text{\sc aoi}}} -
\frac{\text{Time}_{\text{Robot}}^{\text{\sc
aoi}}}{\text{Area}_{\text{Robot}}^{\text{\sc aoi}}} \right |}{N}
\]
}

\emph{Time} and \emph{Area} are normalized, respectively for the total
video length and the total area of the AOIs.

\subsubsection{Questionnaires Processing}
\label{questionnaires_processing}

Questionnaires were coded and two values, the \emph{initial tendency to
anthropomorphize} \anti{} and the \emph{final tendency to anthropomorphize} \antf{}
were computed, respectively from the pre- and post-questionnaires.

These values were computed by a direct sum of the rating provided by the
participants for the Godspeed's questions in the categories
\emph{anthropomorphism} and \emph{likeability}. These ten questions were rated
between -2 and 2, hence \anti{} and \antf{} vary between -20 and 20. The other
questions were not used for this study.

\section{Results}

Based on the experiments conducted on 56 participants in the human and robot
interactions across \emph{shallow} and \emph{deep cognitive priming} conditions,
we have the following results.\footnote{The detailed statistics and code used
    for obtaining the results are available here :
\url{https://github.com/chili-epfl/anthropomorphism-eyetracking}.}

\subsection{General Biases}

While testing for all the 4 hypotheses, we observed no significant bias with
respect to age, gender, familiarity with robot and robot ownership
of the participants, \ie there was no effects to be found between these factors
and the other variables of the experiment.

\subsection{Manipulation Check}

\begin{figure}
    \centering
    \includegraphics[width=7cm]{ManipulationCheck}
    \caption{Average ratings for the manipulation check question}
    \label{fig:ManipulationCheck}
\end{figure}


Participants were asked in the post-questionnaire whether the video presented a
\emph{``robot kind of task''} or a \emph{``human kind of task''} on a 5-points
scale (numerical values ranging from -2 to 2, where -2 refers to robot kind of
task). As can be seen in figure 2, we got a significant correlation in this
manipulation check ($F(1,54) = 29.0, p < .001$) which validates our manipulation
and supports \h{1}: the participants that were shown the \emph{shallow cognitive
context} videos identified the task as more robot-like and participants watching
the videos with deeper cognitive priming perceived the tasks as more human-like. 


\subsection{Impact of the Tendency to Anthropomorphize on Human
Gazing Behaviours}

We found a significant correlation between
$\delta_{\mathcal{H},\mathcal{R}}^{\text{gaze}}$ and
the \anti{}. As seen in figure~\ref{h2}, there is a significant negative
correlation between the two quantities (Pearson Correlation Coefficient $r(54) = -0.43,
p < .001$). The higher the (initial) tendency to anthropomorphize, the smaller
the difference in gazing behaviours between the robot and human conditions. This
supports hypothesis \h{2}.

\begin{figure}
    \centering
    \includegraphics[width=0.5\columnwidth]{H2}\label{GazeDifference-vs-ICA}
    \caption{Gaze distribution difference $\delta_{\mathcal{H},
    \mathcal{R}}^{\text{gaze}}$ \vs initial tendency to anthropomorphize \anti{}}
    \label{h2}
\end{figure}

\subsection{Gaze Behaviours in Response to Shallow \vs Deep Cognitive Priming}

We consider the 5 groups of AOIs {\sf head}, {\sf arms}, {\sf hands}, {\sf
torso} and {\sf legs} (the left and right arms, hands and legs are grouped
together). Based on ANOVA results for the robot in both the shallow and deep
cognitive priming conditions, the fixations on the head in the deep condition
were found to be significantly higher than that in the shallow condition
($F(1,54) = 4.2, p < .05$\fixme{put the exact p value here}). For all other AOIs groups, the fixations across
shallow and deep conditions were almost the same. Figure~\ref{h3} shows the
distribution of proportion of time spent gazing on the 5 AOI groups for the two
conditions.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.6\columnwidth]{GazeHighLow}\label{GazeHighLow}
    \caption{Gaze fixations on the different areas on interest, for shallow \vs
    deep cognitive priming conditions.}
    \label{h3}
\end{figure}

This constitutes the main result of this study: inducing a deeper cognitive
context for the same interaction suffices to lead to significantly longer
fixations on the agent's head (hypothesis \h{3}).

Note that we only analysed these possible correlations for robot condition: in
the human condition, the presence of the human is intrinsically a source of deep
cognitive expectations, hiding the effects of our manipulation on a shallow \vs deep
cognitive priming.


\subsection{Correlation Between Cognitive Priming and Changes in Anthropomorphic
Attributions}

Running an ANOVA against the change of anthropomorphic attributions
(\deltaant) over the duration of the experiment in the two cognitive
conditions, shows that \deltaant is greater for tasks with a deeper cognitive
context than that for the shallow cognitive tasks ($F(1,54) = 6.54, p <
.05$\fixme{put the exact p value here},
figure~\ref{h4}). In other words, after being exposed to short videos of a robot
performing simple tasks, participants primed with a deeper cognitive
expectations report a significantly higher tendency to anthropomorphize robots
\emph{in general} (as the questionnaire on anthropomorphic attributions
explicitly referred to \emph{robots in general}).

\begin{figure}
    \centering
    \includegraphics[width=3.3in]{H4}\label{ICAtoAAPImprovement}
    \caption{Difference between \anti{} and \antf{} in the shallow and deep
    cognitive priming conditions.}
    \label{h4}
\end{figure}

This result supports \h{4} and validate that the cognitive priming impacts the
attribution of anthropomorphic features to robots. This, in turn, supports the
\emph{proxy} hypothesis of \h{3}: \emph{head fixations are a proxy for higher
levels of human-likeness attributions}.

%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}

\subsection{Discussion of the Results}

The presented results bring some light on our initial hypotheses.

The significant correlation between deep \vs shallow conditions and the
answers to the question \emph{Were the task more robot-like or human-like?}
shows that our manipulation was successful, and that a shallow cognitive
context was indeed associated to a robot-like situation, while a deeper
cognitive priming was associated to a human-like situation (\h{1}). This is
already an interesting result: subtle changes in the cognitive priming are
recognized and clearly interpreted in terms of human-likeness.

Hypothesis \h{2} looked at a possible interaction between our tendency to
anthropomorphize (as measured in the pre-questionnaire) and our actual gaze
behaviour, the hypothesis being that high anthropomorphizers would show smaller
differences between the way they look at robots and humans (since they would
consider robots closer to humans than low anthropomorphizers). Our data supports
this hypothesis: participants reporting an higher tendency to anthropomorphize
tend to have closer gazing behaviours when they look at humans or at robots:
statistically speaking, the tendency to anthropomorphize robots
is reflected in the way one looks at them: you look at them
like you would look at humans.

The third hypothesis \h{3} proposes that head fixations are related to the
cognitive expectations, which is clearly supported by our data: after deeper cognitive
priming, one tends to spend more time looking at the head of the interacting
agent than after shallow cognitive priming. We also hypothesized that, in turn,
head fixations could act as a \emph{proxy to anthropomorphic projections}: as
underlined in the previous section, our data also support this.

Finally, the hypothesis \h{4} looks at the dynamic of anthropomorphic
projections, with the hypothesis that watching an interaction with a particular
robot after a deeper cognitive priming may impact \emph{globally} the
anthropomorphic perceptions of robots. This is supported by our study.

\subsection{Design of the Stimuli and Applicability of the Method to Real World
Scenarios}
\label{stimuli_design}

The video stimuli had to obey to several constraints: they had to depict
plausible and legible situations, yet simple enough to be suitable for an
eye-tracking study (simple mechanics, easily distinguishable elements at
predictable locations). The body parts of the robot or human would need remain
visible most of the time. The actions had to be meaningful for both a robot and
a human, and both should be able to perform them in similar ways (similar pace,
similar movements) without looking ackward.

Finally, the situations needed to support two possible kind of cognitive priming
(shallow \vs deeper cognitive priming), and triggering one or the other of these
contexts needed to be done \emph{without changing} the visual part of the
stimulus.

We initially prepared three different stimuli: the \emph{Picking} task, the
\emph{Pointing} task and a \emph{Dance} task.  During the \emph{Dance} task, the
agent was either asked to \emph{``Show some movements''} (\emph{shallow
cognitive priming} condition) or to \emph{``Dance with the music''}
(\emph{deeper cognitive priming} condition). While all the participants were
shown this stimuli as well, we decided to exclude it from the results as we
found out that the nature of the task (participants had to watch body movements)
introduced an experimental bias: because dance is a form of whole-body
expression, gazes where evenly distributed on the body of the agents, masking
possible cognition-related gaze patterns.

This underlines the difficulty of designing appropriate stimuli and raises the
question of the applicability of our method to real-world, ``in the wild''
human-robot interaction.

Two main comments can be made: first, we had to carefully design those stimuli
to \emph{evidence} the link between the (anthropomorphic) perception of a robot
and actual gaze fixations on the face of the robot. This being granted,
researchers will not have to design their scenarios in such a constraint way to
rely on our result, \ie the link between perception and gaze behaviour.

Besides, one may point that, in real-world experiments, the robot does not
always remain in the field of view of the participant, and, at the very least, the
body of the robot may be partially occluded at time.  This is certainly true,
and while new experiments would be welcome to validate it, we believe that our
method remains effective in these situations. First it relies on the
\emph{ratio} of the gaze fixations on the head \vs gaze fixations on other parts
of the body, thus compensating for out-of-sight robots; second, our method
\emph{does not} provide an \emph{absolute} measurement of the level
anthropomorphic perception, but rather a \emph{relative} measurement: within a
group of participants, it enables to classify participants in term of their level of
projected anthropomorphism onto the robot.  This means that, while this method
can not be used to assess the perception of robots between different interaction
situations (\ie different experiments), it can be employed within a group a
participants taking part to the same experiment.

Lastly, the stationary eye-tracker would also have to be replaced by a mobile
eye-tracker. This would however not impact the interpretation of the results.

\section{Conclusion}

The study and results presented in this article lead to two main contributions:
new insights on the impact of the cognitive priming on the perception of a robot
by humans; a novel unbiased methodology based on eye-tracking to assess
anthropomorphic attributions during a running human-robot interaction.

Our first contribution extends our understanding of the attribution of
human-like characteristics to robot by exploring the role of the interaction
context. As we show, it appears that even relatively subtle context
priming may lead to significantly different anthropomorphic perceptions of
the exact same robot, performing the exact same task, as confirmed both by
distinct gaze patterns, and different reported perceptions in questionnaires.
Interestingly, this effects can already be evidenced after very short,
one-way, interactions (less than 2 minutes).

This leads to a second-order effect that we also evidence here: depending on the
cognitive priming, the tendency to attribute human-like characteristics to robot
evolves in significantly different ways. After observing a robot in a
context that presupposes deeper cognitive capabilities, people increase
their general tendency to anthropomorphize robots compared to a shallow
cognitive priming, even though the robot appearance and visual behaviour is the
exact same.

The second contribution is a methodological one: we present in this article
a novel technique to assess anthropomorphic projections that relies on a
biometric measurement (eye-tracking) to compare gaze fixation durations on
the face of the robot. We cross-validate this new metric with existing,
established, questionnaires. Compared to current techniques (post-hoc
annotations of videos and questionnaires), this new approach is objective,
is less impacted by experimental biases (like the \emph{observer effect},
where the behaviour of the participant is impacted by the fact he/she knows that
he/she is observed) and take place during the interaction itself
(\emph{in-the-moment} measurement).

Besides, we also introduce a new kind of visual stimuli, specifically designed
to study the impact of non-appearance, non-behavioural related effects on the
human-like perception of robots. We make these video stimuli available to the
community, and therefore invite our colleagues to reproduce our experimental
results. The next section describe the specificities of these stimuli, and also
discuss how such a methodology can apply to real-world scenarios.

As a whole, the article attempts to contribute to our understanding of an
intricate psychological effects that come to play when humans and robots
interact, both in terms of methodology and experimental evidence.

\fixme{Properly conclude the paper: what does our research reveals?}

\section*{Acknowledgments}

We would like here to acknowledge the contribution of Julia Fink to a better
understanding of anthropomorphism as a psychological phenomenon. We also thank
all the students for their participation.

This research was supported by the Swiss National Science Foundation through the
National Centre of Competence in Research Robotics.


\bibliographystyle{apacite}
\bibliography{biblio}

%\appendix
%\includepdf[pages={1,2}]{pre-questionnaire.pdf}
%\includepdf[pages={1,2}]{post-questionnaire.pdf}

\end{document}
